import stanza

def tokenizerStanza():
    nlp = stanza.Pipeline("es", processors='tokenize, mwt', use_gpu=False)
    #nlp = stanza.Pipeline("es")
    textoEn = "I can't believe John's cafÃ©â€”where they sell New York-style bagelsâ€”isn't open 24/7 anymore... What're they thinking? ðŸ¤” Anyway, Iâ€™ve gotta go pick up some groceriesâ€”milk, bread, eggs, etc.â€”before heading to grandma's house for her birthday party at 5:00 p.m. Oh, btw, are we still on for the AI workshop next Fri?"
    textoEs = "Â¡No puedo creerlo! Juan's CafÃ©â€”donde venden pan reciÃ©n hecho, tipo francÃ©sâ€”cerrÃ³ temprano hoy... Â¿QuÃ© estarÃ¡n pensando? ðŸ˜• En fin, voy a recoger unas cosas: leche, pan, huevos, etc., antes de ir a casa de mi abuela para su fiesta de cumpleaÃ±os a las 17:00. Ah, por cierto, Â¿seguimos con la reuniÃ³n de Inteligencia Artificial el prÃ³ximo viernes?"
    doc = nlp(textoEs)
    for sentence in doc.sentences:
        for word in sentence.words:
            print(word.lemma)
    #print(doc)

if __name__ == '__main__':
    tokenizerStanza()
